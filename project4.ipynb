{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.stats import ttest_ind, chi2_contingency\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleveland.csv')\n",
    "\n",
    "# Rename 'num' column to 'disease' and change 1,2,3,4 to 1\n",
    "df = df.rename({'num':'disease'}, axis=1)\n",
    "df['disease'] = df.disease.apply(lambda x: min(x, 1))\n",
    "\n",
    "# get rid of missing data\n",
    "df.replace('?', np.nan, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding good features\n",
    "\n",
    "here, we categorize the different kinds of data that we have, and then compare the distribution of that feature in both populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric = [\n",
    "    'age',\n",
    "    'trestbps',\n",
    "    'chol',\n",
    "    'thalach',\n",
    "    'oldpeak',\n",
    "]\n",
    "\n",
    "categorical = [\n",
    "    'sex',\n",
    "    'cp',\n",
    "    'fbs',\n",
    "    'restecg',\n",
    "    'exang',\n",
    "    'slope',\n",
    "    'ca',\n",
    "    'thal',\n",
    "]\n",
    "\n",
    "fig, axs = plt.subplots(ncols=5, figsize=(20, 5))\n",
    "fig.suptitle('Numeric Features by presense of disease')\n",
    "for i in range(len(numeric)):\n",
    "    sns.kdeplot(data=df, x=numeric[i], hue='disease', ax=axs[i], fill=True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig, axs = plt.subplots(ncols=4, nrows=2, figsize=(20, 10))\n",
    "fig.suptitle('Categorical Features by presense of disease')\n",
    "for i in range(len(categorical)):\n",
    "    sns.countplot(data=df, x=categorical[i], hue='disease', ax=axs[i//4][i%4])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From those graphs, there are some suspicious features. specifically, I will investigate if there is a correlation between disease and:\n",
    "1. age\n",
    "2. thalach\n",
    "3. oldpeak\n",
    "4. sex\n",
    "5. cp\n",
    "6. slope\n",
    "7. ca\n",
    "8. thal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test if there is a difference in the means between the two groups for each numeric feature\n",
    "print('t-test for age')\n",
    "print(ttest_ind(df[df.disease == 0].age, df[df.disease == 1].age))\n",
    "print('t-test for thalach')\n",
    "print(ttest_ind(df[df.disease == 0].thalach, df[df.disease == 1].thalach))\n",
    "print('t-test for oldpeak')\n",
    "print(ttest_ind(df[df.disease == 0].oldpeak, df[df.disease == 1].oldpeak))\n",
    "\n",
    "# test if there is a difference in the distribution of the categorical features between the two groups\n",
    "print('chi2 test for sex')\n",
    "print(chi2_contingency(pd.crosstab(df.sex, df.disease)))\n",
    "print('chi2 test for cp')\n",
    "print(chi2_contingency(pd.crosstab(df.cp, df.disease)))\n",
    "print('chi2 test for slope')\n",
    "print(chi2_contingency(pd.crosstab(df.slope, df.disease)))\n",
    "print('chi2 test for ca')\n",
    "print(chi2_contingency(pd.crosstab(df.ca, df.disease)))\n",
    "print('chi2 test for thal')\n",
    "print(chi2_contingency(pd.crosstab(df.thal, df.disease)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From that it looks like all of the selected attributes are extremely likely to be correlated with the presence of heart dis|ease.\n",
    "\n",
    "We will select all of these features for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [\n",
    "    'age_s',\n",
    "    'thalach_s',\n",
    "    'oldpeak_s',\n",
    "    'sex',\n",
    "    'cp',\n",
    "    'slope',\n",
    "    'ca',\n",
    "    'thal',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardizing Attributes\n",
    "\n",
    "In this case, the categorical features will not be standardized in any way. This is fine because all of the selected categorical features are either binary or ordinal, and thus the numeric representations make sense as euclidean dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# standardize numeric features\n",
    "df['age_s'] = (df.age - df.age.mean())/df.age.std()\n",
    "df['thalach_s'] = (df.thalach - df.thalach.mean())/df.thalach.std()\n",
    "df['oldpeak_s'] = (df.oldpeak - df.oldpeak.mean())/df.oldpeak.std()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K optimization\n",
    "\n",
    "We will now use k-fold cross-validation to test the performance of the model with k values ranging from 1 to 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split, cross_validate, KFold, GridSearchCV\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "# Create a function for prediction and evaluation\n",
    "def predict_and_evaluate(X, y, k_values, n_splits=10):\n",
    "    results = []\n",
    "\n",
    "    # Perform K-Fold cross-validation\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True)\n",
    "\n",
    "    for k in k_values:\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            # Create nearest neighbors object\n",
    "            nn = NearestNeighbors(n_neighbors=k, metric='euclidean', algorithm='auto')\n",
    "            nn.fit(X_train)\n",
    "\n",
    "            # Find the k nearest neighbors to the test set\n",
    "            distances, indices = nn.kneighbors(X_test)\n",
    "\n",
    "            for i in range(len(X_test)):\n",
    "                nbrs_diseased = y_train[indices[i]].flatten()\n",
    "                predict = pd.Series(nbrs_diseased).mode()[0]  # Most common label\n",
    "                y_pred.append(predict)\n",
    "                y_true.append(y_test[i][0])\n",
    "\n",
    "        # Calculate precision, recall, and F1 scores\n",
    "        (p, r, f, s) = precision_recall_fscore_support(y_true, y_pred, labels=[1])\n",
    "        results.append((k, p, r, f, s))\n",
    "\n",
    "    return results\n",
    "\n",
    "# Main execution\n",
    "X = df[selected_features].values\n",
    "y = df[['disease']].values\n",
    "\n",
    "\n",
    "# Define the range of k values to try\n",
    "k_values = range(1, 201)  # Test k from 1 to 120\n",
    "results = predict_and_evaluate(X, y, k_values)\n",
    "\n",
    "# # Print the results\n",
    "# for k, p, r, f, s in results:\n",
    "#     print(f'k={k}, precision={p}, recall={r}, f-score={f}, support={s}')\n",
    "\n",
    "plt.plot([x[0] for x in results], [x[3] for x in results])\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('F1 Score')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The f1-score appears to be the highest when k is near 10, so we will select that as our k value. Interestingly, we see two maxima for this graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Challenge Dataset (replace with name of test file)\n",
    "df = pd.read_csv('cleveland-test-sample.csv')\n",
    "\n",
    "# Rename 'num' column to 'disease' and change 1,2,3,4 to 1\n",
    "df = df.rename({'num':'disease'}, axis=1)\n",
    "df['disease'] = df.disease.apply(lambda x: min(x, 1))\n",
    "\n",
    "# get rid of missing data\n",
    "df.replace('?', np.nan, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# standardize numeric features\n",
    "df['age_s'] = (df.age - df.age.mean())/df.age.std()\n",
    "df['thalach_s'] = (df.thalach - df.thalach.mean())/df.thalach.std()\n",
    "df['oldpeak_s'] = (df.oldpeak - df.oldpeak.mean())/df.oldpeak.std()\n",
    "\n",
    "X = df[selected_features].values\n",
    "y = df[['disease']].values\n",
    "\n",
    "nn = NearestNeighbors(n_neighbors=10, metric='euclidean', algorithm='auto')\n",
    "\n",
    "nn.fit(X)\n",
    "\n",
    "distances, indices = nn.kneighbors(X)\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "for i in range(len(X)):\n",
    "    nbrs_diseased = y[indices[i]].flatten()\n",
    "    predict = pd.Series(nbrs_diseased).mode()[0]  # Most common label\n",
    "    y_pred.append(predict)\n",
    "    y_true.append(y[i][0])\n",
    "\n",
    "(p, r, f, s) = precision_recall_fscore_support(y_true, y_pred, labels=[1])\n",
    "print(f'precision={p}, recall={r}, f-score={f}, support={s}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
